{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: _____\n",
    "\n",
    "Nome: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ivanp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import prod\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\ivanp\\OneDrive\\Documentos\\INSPER\\2o. Semestre_2022\\C.Dados\\22-2a-cd-p1-grupo_rafaeldbo\\notebooks\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as notícias classificadas manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/dados.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No total, foram classificadas 1400 notícias\n",
      "0: 206 (14.713999999999999)\n",
      "1: 310 (22.142999999999997)\n",
      "2: 206 (14.713999999999999)\n",
      "3: 678 (48.429)\n",
      "No total, foram classificadas 1000 notícias na planilha de treinamento\n",
      "0: 102 (10.2)\n",
      "1: 248 (24.8)\n",
      "2: 160 (16.0)\n",
      "3: 490 (49.0)\n",
      "No total, foram classificadas 1000 notícias na planilha de teste\n",
      "0: 104 (26.0)\n",
      "1: 62 (15.5)\n",
      "2: 46 (11.5)\n",
      "3: 188 (47.0)\n"
     ]
    }
   ],
   "source": [
    "quantidade_train = train.value_counts('Target', sort=False)\n",
    "quantidade_test = test.value_counts('Target',  sort=False)\n",
    "# display(quantidade_train.to_frame())\n",
    "# display(quantidade_test.to_frame())\n",
    "\n",
    "quant_0 = quantidade_test[0]+quantidade_train[0]\n",
    "quant_1 = quantidade_test[1]+quantidade_train[1]\n",
    "quant_2 = quantidade_test[2]+quantidade_train[2]\n",
    "quant_3 = quantidade_test[3]+quantidade_train[3]\n",
    "total = sum(quantidade_train) + sum(quantidade_test)\n",
    "total_train = sum(quantidade_train)\n",
    "total_test = sum(quantidade_test)\n",
    "\n",
    "print(f'No total, foram classificadas {total} notícias')\n",
    "print(f\"0: {quant_0} ({round(quant_0/total, 5)*100})\")\n",
    "print(f\"1: {quant_1} ({round(quant_1/total, 5)*100})\")\n",
    "print(f\"2: {quant_2} ({round(quant_2/total, 5)*100})\")\n",
    "print(f\"3: {quant_3} ({round(quant_3/total, 5)*100})\")\n",
    "\n",
    "print(f'No total, foram classificadas {total_train} notícias na planilha de treinamento')\n",
    "print(f\"0: {quantidade_train[0]} ({round(quantidade_train[0]/total_train, 5)*100})\")\n",
    "print(f\"1: {quantidade_train[1]} ({round(quantidade_train[1]/total_train, 5)*100})\")\n",
    "print(f\"2: {quantidade_train[2]} ({round(quantidade_train[2]/total_train, 5)*100})\")\n",
    "print(f\"3: {quantidade_train[3]} ({round(quantidade_train[3]/total_train, 5)*100})\")\n",
    "\n",
    "print(f'No total, foram classificadas {total_train} notícias na planilha de teste')\n",
    "print(f\"0: {quantidade_test[0]} ({round(quantidade_test[0]/total_test, 5)*100})\")\n",
    "print(f\"1: {quantidade_test[1]} ({round(quantidade_test[1]/total_test, 5)*100})\")\n",
    "print(f\"2: {quantidade_test[2]} ({round(quantidade_test[2]/total_test, 5)*100})\")\n",
    "print(f\"3: {quantidade_test[3]} ({round(quantidade_test[3]/total_test, 5)*100})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação das notícias (Target).\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [estudo, faculdade, medicina, universidade, ho...\n",
       "1      [crescente, popularidade, impulsionado, aument...\n",
       "2      [variante, ba, 2, cepa, ômicron, coronavírus, ...\n",
       "3      [número, novos, casos, mortes, covid, 19, amér...\n",
       "4      [plataforma, streaming, cria, regras, contra, ...\n",
       "                             ...                        \n",
       "995    [pudesse, decidir, que, preferiria, ir, a, lua...\n",
       "996    [primeiro, africano, liderar, organização, mun...\n",
       "997    [sabe, preguiça, dá, guardar, compras, você, c...\n",
       "998    [juíza, responsável, decidir, bilionário, elon...\n",
       "999    [vacinação, contra, covid, 19, crianças, 5, 11...\n",
       "Name: Descrição_Limpo, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limpador\n",
    "stopWords = stopwords.words('portuguese')\n",
    "lista_elementos= ',.@!#$%¨&*()–_-“”:;+‘’={[}]?/\\|…\"\"><'\n",
    "def cleanup (texto):\n",
    "    texto= texto.strip().lower()\n",
    "    for letra in lista_elementos:\n",
    "        texto= texto.replace(letra, \" \")\n",
    "    texto= texto.strip().split()\n",
    "    for palavra in texto:\n",
    "        if palavra in stopWords:\n",
    "            texto.remove(palavra)\n",
    "    return texto\n",
    "train[\"Título_Limpo\"]= train[\"Titulo\"].apply(cleanup)\n",
    "train[\"Descrição_Limpo\"]= train[\"Descrição\"].apply(cleanup)\n",
    "train[\"Título_Limpo\"]\n",
    "train[\"Descrição_Limpo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "allWords = []\n",
    "for wordsList in train['Descrição']:\n",
    "    allWords += list(wordsList.split())\n",
    "allWords = pd.Series(allWords)\n",
    "portuguese = list(set(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Target            0     1    2     3\n",
       "Classificacao                       \n",
       "0               3.5   0.0  0.2   0.5\n",
       "1               3.0  10.2  4.0   9.0\n",
       "2               2.0   1.0  1.5   0.8\n",
       "3              17.5   4.2  5.8  36.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fazendo o filtro de cada Target\n",
    "filter_neutral= train[\"Target\"] == 0\n",
    "filter_very_bad= train[\"Target\"] == 1\n",
    "filter_bad= train[\"Target\"] == 2\n",
    "filter_good= train[\"Target\"] == 3\n",
    "\n",
    "#Aplicando o filtro na base de treinamento\n",
    "train_neutral= train.loc[filter_neutral,:]\n",
    "train_bad= train.loc[filter_bad,:]\n",
    "train_very_bad= train.loc[filter_very_bad,:]\n",
    "train_good= train.loc[filter_good,:]\n",
    "\n",
    "#Criando a lista de palavras de cada target\n",
    "list_neutral_words= train_neutral[\"Descrição_Limpo\"].sum(axis= 0)\n",
    "list_bad_words= train_bad[\"Descrição_Limpo\"].sum(axis= 0)\n",
    "list_very_bad_words= train_very_bad[\"Descrição_Limpo\"].sum(axis= 0)\n",
    "list_good_words= train_good[\"Descrição_Limpo\"].sum(axis= 0)\n",
    "\n",
    "#Criando um series para cada target\n",
    "series_neutral= pd.Series(list_neutral_words)\n",
    "series_bad= pd.Series(list_bad_words)\n",
    "series_very_bad= pd.Series(list_very_bad_words)\n",
    "series_good= pd.Series(list_good_words)\n",
    "\n",
    "#Fazendo a frequencia absoluta\n",
    "table_neutral= series_neutral.value_counts()\n",
    "table_bad= series_bad.value_counts()\n",
    "table_very_bad= series_very_bad.value_counts()\n",
    "table_good= series_good.value_counts()\n",
    "\n",
    "#Fazendo a probabilidade de cada target\n",
    "prob_neutral= (len(list_neutral_words)/len(allWords))\n",
    "prob_bad= (len(list_bad_words)/len(allWords))\n",
    "prob_very_bad= (len(list_very_bad_words)/len(allWords))\n",
    "prob_good= (len(list_good_words)/len(allWords))\n",
    "\n",
    "# Suavizador de Laplace\n",
    "def laplace_smoothing(wordsList, amount):\n",
    "    laplace_amount = amount + 1\n",
    "    density = len(wordsList) + len(portuguese)\n",
    "    laplace = laplace_amount/density\n",
    "    return laplace\n",
    "\n",
    "#sendo wordsList = series de todas as palavras de um target\n",
    "#sendo amount = quantidade de vezes que determinada palavra aparece lista do target (frequência absoluta)\n",
    "\n",
    "#Função probabilidade do target \n",
    "def probability_target(table_target, series_target, news):\n",
    "    \n",
    "    list_target= []\n",
    "    for word in news:\n",
    "        if word in table_target.keys():\n",
    "            amount= table_target[word]\n",
    "        else:\n",
    "            amount= 0\n",
    "        list_target.append(laplace_smoothing(series_target, amount))\n",
    "        \n",
    "    probability_target= np.prod(list_target)\n",
    "    return probability_target\n",
    "\n",
    "#Função do Naive Bayes\n",
    "def naive_bayes(news):\n",
    "    prob_0= probability_target(table_neutral, series_neutral, news) * prob_neutral\n",
    "    prob_1= probability_target(table_very_bad, series_very_bad, news) * prob_very_bad\n",
    "    prob_2= probability_target(table_bad, series_bad, news) * prob_bad\n",
    "    prob_3= probability_target(table_good, series_good, news) * prob_good\n",
    "    list_probs= [prob_0,prob_1,prob_2,prob_3]\n",
    "    target= list_probs.index(max(list_probs))\n",
    "    return target\n",
    "    \n",
    "test[\"Descrição_Limpo\"]= test[\"Descrição\"].apply(cleanup)\n",
    "test[\"Classificacao\"]= test[\"Descrição_Limpo\"].apply(naive_bayes)\n",
    "\n",
    "pd.crosstab(test[\"Classificacao\"],test[\"Target\"],normalize=True).round(3) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das notícias entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas notícias. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas caterogias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por caterogia (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb7af8c955b36ac4d04fa9969eb33b8c629734543e89e2f9358555e6c3f18d8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
